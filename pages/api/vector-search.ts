import type { NextApiRequest, NextApiResponse } from 'next'
import { createClient } from '@supabase/supabase-js'
import { codeBlock, oneLine } from 'common-tags'
import GPT3Tokenizer from 'gpt3-tokenizer'
import OpenAI from 'openai'
import { ApplicationError, UserError } from '@/lib/errors'

const openAiKey = process.env.OPENAI_KEY
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY

// @ts-ignore - OpenAI v4 SDK default export is a constructible client
const openai = new OpenAI({ apiKey: openAiKey })

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  try {
    console.log('ğŸš€ Vector search API í˜¸ì¶œ ì‹œì‘')
    console.log('ğŸ“‹ ìš”ì²­ ë©”ì„œë“œ:', req.method)
    console.log('ğŸ”§ í™˜ê²½ë³€ìˆ˜ í™•ì¸:', {
      hasOpenAiKey: !!openAiKey,
      hasSupabaseUrl: !!supabaseUrl,
      hasSupabaseServiceKey: !!supabaseServiceKey,
    })

    if (!openAiKey) {
      throw new ApplicationError('Missing environment variable OPENAI_KEY')
    }

    if (!supabaseUrl) {
      throw new ApplicationError('Missing environment variable SUPABASE_URL')
    }

    if (!supabaseServiceKey) {
      throw new ApplicationError('Missing environment variable SUPABASE_SERVICE_ROLE_KEY')
    }

    const requestData = req.body
    console.log('ğŸ“¦ ìš”ì²­ ë°ì´í„° íƒ€ì…:', typeof requestData)
    console.log('ğŸ“¦ ìš”ì²­ ë°ì´í„° ì¡´ì¬ì—¬ë¶€:', !!requestData)

    if (!requestData) {
      throw new UserError('Missing request data')
    }

    const { prompt: query } = requestData
    const wantsStream = requestData?.stream === true || requestData?.stream === 'true'
    console.log('ğŸ” ì¿¼ë¦¬ ê¸¸ì´:', query?.length || 0)
    console.log('ğŸ” ì¿¼ë¦¬ ë¯¸ë¦¬ë³´ê¸°:', query?.substring(0, 100))
    console.log('ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€:', wantsStream)

    if (!query) {
      throw new UserError('Missing query in request data')
    }

    const supabaseClient = createClient(supabaseUrl, supabaseServiceKey)

    // Moderate the content to comply with OpenAI T&C
    const sanitizedQuery = query.trim()
    console.log('ğŸ›¡ï¸ OpenAI ê²€ì—´ ì‹œì‘...')

    const moderationResponse = await openai.moderations.create({
      model: 'omni-moderation-latest',
      input: sanitizedQuery,
    })

    console.log('ğŸ›¡ï¸ ê²€ì—´ ì‘ë‹µ:', moderationResponse)
    console.log('ğŸ›¡ï¸ ê²€ì—´ ì™„ë£Œ, ê²°ê³¼:', moderationResponse.results?.length > 0 ? 'OK' : 'ERROR')

    // Vercel í™˜ê²½ì—ì„œ moderationResponse.resultsê°€ undefinedì¼ ìˆ˜ ìˆìŒ
    if (
      !moderationResponse.results ||
      !Array.isArray(moderationResponse.results) ||
      moderationResponse.results.length === 0
    ) {
      console.log('âŒ ê²€ì—´ ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ:', moderationResponse)
      throw new ApplicationError('Invalid moderation response from OpenAI')
    }

    const [results] = moderationResponse.results

    if (results.flagged) {
      console.log('ğŸš« ì½˜í…ì¸  í”Œë˜ê·¸ë¨:', results.categories)
      throw new UserError('Flagged content', {
        flagged: true,
        categories: results.categories,
      })
    }

    // LLM ê¸°ë°˜ ì¸í…íŠ¸ ë¶„ë¥˜
    console.log('ğŸ§­ ì¸í…íŠ¸ ë¶„ë¥˜ ì‹œì‘...')
    let classifiedIntent: string = 'legal_question'
    let classifiedConfidence = 0
    const tryParseIntentJson = (text: string) => {
      try {
        return JSON.parse(text)
      } catch (_) {
        const m = text.match(/\{[\s\S]*\}/)
        if (m) {
          return JSON.parse(m[0])
        }
        return null
      }
    }
    try {
      const intentSystem = oneLine`
        ë‹¹ì‹ ì€ í•œêµ­ì–´ ë²•ë¥  ìƒë‹´ ë„ë©”ì¸ì˜ ì¸í…íŠ¸ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
        "greeting" | "legal_question" | "smalltalk" | "non_legal" | "other".
        ë°˜ë“œì‹œ ì—„ê²©í•œ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. í˜•ì‹: {"intent":"...","confidence":0.0~1.0}
        ì„¤ëª…, ì¶”ê°€ í…ìŠ¤íŠ¸, ì½”ë“œë¸”ë¡ ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.`
      const intentResp = await openai.chat.completions.create({
        model: 'gpt-5-mini',
        //temperature: 0,
        messages: [
          { role: 'system', content: intentSystem },
          { role: 'user', content: sanitizedQuery },
        ],
      })
      const rawIntentText = intentResp.choices?.[0]?.message?.content ?? ''
      console.log('ğŸ§­ ì¸í…íŠ¸ ì›ë¬¸ ì‘ë‹µ:', rawIntentText)
      const parsed = tryParseIntentJson(rawIntentText)
      if (parsed?.intent) classifiedIntent = String(parsed.intent)
      if (typeof parsed?.confidence === 'number') classifiedConfidence = parsed.confidence
      if (!parsed) {
        console.warn('âš ï¸ ì¸í…íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©')
      }
    } catch (e) {
      console.warn('âš ï¸ ì¸í…íŠ¸ ë¶„ë¥˜ í˜¸ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', e)
    }

    console.log('ğŸ§­ ì¸í…íŠ¸ ë¶„ë¥˜ ê²°ê³¼:', { classifiedIntent, classifiedConfidence })

    // ì¸ì‚¬/ìŠ¤ëª°í†¡/ë¹„ë²•ë¥  ëŒ€ì‘ì€ RAG ìƒëµ í›„ ì¦‰ì‹œ ì‘ë‹µ
    if (classifiedIntent === 'greeting' || classifiedIntent === 'smalltalk') {
      const greetingAnswer = [
        'ì•ˆë…•í•˜ì„¸ìš”! ë²•ë¬´ ìƒë‹´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì–´ë–¤ ë²•ì  ë¬¸ì˜ë¥¼ ë„ì™€ë“œë¦´ê¹Œìš”?\n',
        '- ì˜ˆ: ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?\n',
        '- ì˜ˆ: ì§ì¥ì—ì„œ ë¶€ë‹¹í•œ ëŒ€ìš°ë¥¼ ë°›ì•˜ì„ ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\n',
        '- ì˜ˆ: ì„ëŒ€ì°¨ ê³„ì•½ ë§Œë£Œ í›„ ë³´ì¦ê¸ˆ ë°˜í™˜ ì ˆì°¨ê°€ ê¶ê¸ˆí•´ìš”.',
      ].join('\n')

      const citationData = {
        type: 'citations',
        sources: [],
        query: sanitizedQuery,
        timestamp: new Date().toISOString(),
      }

      if (wantsStream) {
        res.writeHead(200, {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          Connection: 'keep-alive',
        })
        res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
        res.write(greetingAnswer)
        res.write(`\n\n<!-- END_CITATIONS: 0 sources used -->`)
        return res.end()
      }
      res.writeHead(200, {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      })
      res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
      res.write(greetingAnswer)
      res.write(`\n\n<!-- END_CITATIONS: 0 sources used -->`)
      return res.end()
    }

    if (classifiedIntent === 'non_legal' || classifiedIntent === 'other') {
      const guidanceAnswer = [
        'ì¼ë°˜ ëŒ€í™”ëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ, ì €ëŠ” ë²•ë¥  ê´€ë ¨ ìƒë‹´ì— ìµœì í™”ë˜ì–´ ìˆì–´ìš”.\n',
        'ë²•ì  ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œë©´ ê´€ë ¨ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„ì™€ë“œë¦´ê²Œìš”.\n',
        '- ì˜ˆ: ê·¼ë¡œê³„ì•½ì„œì—ì„œ ì—°ì¥ê·¼ë¡œ ìˆ˜ë‹¹ ê·œì •ì´ ì—†ë‹¤ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n',
        '- ì˜ˆ: ì „ì„¸ê³„ì•½ íŒŒê¸° ì‹œ ìœ„ì•½ê¸ˆì€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?',
      ].join('\n')

      const citationData = {
        type: 'citations',
        sources: [],
        query: sanitizedQuery,
        timestamp: new Date().toISOString(),
      }

      if (wantsStream) {
        res.writeHead(200, {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          Connection: 'keep-alive',
        })
        res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
        res.write(guidanceAnswer)
        res.write(`\n\n<!-- END_CITATIONS: 0 sources used -->`)
        return res.end()
      }
      res.writeHead(200, {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      })
      res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
      res.write(guidanceAnswer)
      res.write(`\n\n<!-- END_CITATIONS: 0 sources used -->`)
      return res.end()
    }

    // Create embedding from query
    console.log('ğŸ”¢ ì„ë² ë”© ìƒì„± ì‹œì‘...')
    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: sanitizedQuery.replaceAll('\n', ' '),
      dimensions: 1536, // 1536 ì°¨ì›ìœ¼ë¡œ ëª…ì‹œì  ì„¤ì •
    })

    console.log('ğŸ”¢ ì„ë² ë”© ì‘ë‹µ êµ¬ì¡°:', {
      hasData: Array.isArray(embeddingResponse.data),
      dataLength: embeddingResponse.data?.length,
    })

    // Vercel í™˜ê²½ì—ì„œ embedding dataê°€ undefinedì¼ ìˆ˜ ìˆìŒ
    if (!embeddingResponse.data || !Array.isArray(embeddingResponse.data) || embeddingResponse.data.length === 0) {
      console.log('âŒ ì„ë² ë”© ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ:', embeddingResponse)
      throw new ApplicationError('Invalid embedding response from OpenAI')
    }

    const [{ embedding }] = embeddingResponse.data

    console.log('ğŸ”¢ ì„ë² ë”© ìƒì„± ì™„ë£Œ, ì°¨ì›:', embedding?.length || 'unknown')

    console.log('ğŸ—„ï¸ Supabase RPC í˜¸ì¶œ ì‹œì‘...')
    
    // ë¨¼ì € í…Œì´ë¸”ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    const { data: totalSections, error: countError } = await supabaseClient
      .from('nods_page_section')
      .select('id, content, heading', { count: 'exact' })
      .limit(5)
    
    console.log('ğŸ“Š í…Œì´ë¸” ë°ì´í„° í™•ì¸:', {
      hasError: !!countError,
      sectionsCount: totalSections?.length || 0,
      firstSection: totalSections?.[0] ? {
        id: totalSections[0].id,
        heading: totalSections[0].heading,
        contentLength: totalSections[0].content?.length || 0
      } : null
    })

    const { error: matchError, data: pageSections } = await supabaseClient.rpc(
      'match_page_sections',
      {
        embedding,
        match_threshold: 0.5, // ì„ê³„ê°’ì„ ë‚®ì¶¤ (0.78 â†’ 0.5)
        match_count: 10,
        min_content_length: 30, // ìµœì†Œ ê¸¸ì´ë„ ë‚®ì¶¤ (50 â†’ 30)
      }
    )

    console.log('ğŸ—„ï¸ RPC ì‘ë‹µ:', {
      hasError: !!matchError,
      errorMessage: matchError?.message,
      pageSectionsType: typeof pageSections,
      pageSectionsLength: Array.isArray(pageSections) ? pageSections.length : 'N/A',
      isArray: Array.isArray(pageSections),
    })

    if (matchError) {
      console.log('âŒ Supabase RPC ì˜¤ë¥˜:', matchError)
      throw new ApplicationError('Failed to match page sections', matchError)
    }

    // Vercel í™˜ê²½ì—ì„œ pageSectionsê°€ undefinedì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°©ì–´ì  ì²˜ë¦¬
    if (!pageSections || !Array.isArray(pageSections)) {
      console.log('âŒ ìœ íš¨í•˜ì§€ ì•Šì€ pageSections:', { pageSections, type: typeof pageSections })
      throw new ApplicationError('No matching page sections found')
    }

    console.log('ğŸ“ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹œì‘...')
    const tokenizer = new GPT3Tokenizer({ type: 'gpt3' })
    let tokenCount = 0
    let contextText = ''
    const usedSections: Array<{
      id: number;
      path: string;
      heading: string;
      similarity: number;
      content_length: number;
      token_count: number;
    }> = []

    for (let i = 0; i < pageSections.length; i++) {
      const pageSection = pageSections[i]
      console.log(`ğŸ“„ ì„¹ì…˜ ${i} ì²˜ë¦¬ ì¤‘:`, {
        hasSection: !!pageSection,
        hasContent: !!pageSection?.content,
        contentType: typeof pageSection?.content,
        contentLength: pageSection?.content?.length || 0,
        similarity: pageSection?.similarity,
        path: pageSection?.path,
        heading: pageSection?.heading,
      })

      // ì„¹ì…˜ ë°ì´í„° ë°©ì–´ì  ì²´í¬
      if (!pageSection || !pageSection.content) {
        console.log(`âš ï¸ ì„¹ì…˜ ${i} ìŠ¤í‚µ: ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°`)
        continue
      }

      const content = pageSection.content
      const encoded = tokenizer.encode(content)
      const sectionTokenCount = encoded.text.length
      
      if (tokenCount + sectionTokenCount >= 1500) {
        console.log('âš ï¸ í† í° í•œë„ ë„ë‹¬, ì„¹ì…˜ ì²˜ë¦¬ ì¤‘ë‹¨:', { ì„¹ì…˜ìˆ˜: i, í† í°ìˆ˜: tokenCount })
        break
      }

      tokenCount += sectionTokenCount
      contextText += `${content.trim()}\n---\n`
      
      // ì‚¬ìš©ëœ ì„¹ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥
      usedSections.push({
        id: pageSection.id || i,
        path: pageSection.path || 'unknown',
        heading: pageSection.heading || 'ì œëª© ì—†ìŒ',
        similarity: pageSection.similarity || 0,
        content_length: content.length,
        token_count: sectionTokenCount,
      })
      
      console.log(`âœ… ì„¹ì…˜ ${i} í¬í•¨ë¨:`, {
        id: pageSection.id,
        path: pageSection.path,
        heading: pageSection.heading?.substring(0, 50),
        similarity: pageSection.similarity,
        tokens: sectionTokenCount,
      })
    }

    console.log('ğŸ“ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ:', {
      ì´ì„¹ì…˜ìˆ˜: pageSections.length,
      ì²˜ë¦¬ëœì„¹ì…˜ìˆ˜: contextText.split('---').length - 1,
      ìµœì¢…í† í°ìˆ˜: tokenCount,
      ì»¨í…ìŠ¤íŠ¸ê¸¸ì´: contextText.length,
    })
    
    // ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ì†ŒìŠ¤ ìƒì„¸ ë¡œê¹…
    console.log('ğŸ“š ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ì†ŒìŠ¤ë“¤:')
    usedSections.forEach((section, index) => {
      console.log(`  [${index + 1}] ${section.path} - ${section.heading}`, {
        similarity: section.similarity.toFixed(4),
        tokens: section.token_count,
        content_chars: section.content_length,
      })
    })

    // ì•ˆì „í•œ í…œí”Œë¦¿ ìƒì„±ì„ ìœ„í•œ ë³€ìˆ˜ë“¤ í™•ì¸
    const safeContextText = contextText || ''
    const safeSanitizedQuery = sanitizedQuery || ''

    console.log('ğŸ“‹ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤€ë¹„:', {
      contextTextLength: safeContextText.length,
      queryLength: safeSanitizedQuery.length,
      hasCodeBlock: typeof codeBlock === 'function',
      hasOneLine: typeof oneLine === 'function',
    })

    const prompt = codeBlock`
      ${oneLine`
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë²•ì  ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ 
        ì‹ ì¤‘í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë²•ì  ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
        ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” "ì œê³µëœ ì •ë³´ë¡œëŠ” 
        ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸°ë¥¼ ê¶Œí•©ë‹ˆë‹¤."ë¼ê³  
        ë‹µë³€í•´ì£¼ì„¸ìš”.
      `}

      ë²•ì  ì •ë³´:
      ${safeContextText}

      ì§ˆë¬¸: """
      ${safeSanitizedQuery}
      """

      ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
      1. ì •í™•í•˜ê³  ì‹ ì¤‘í•œ ë²•ì  ì¡°ì–¸ ì œê³µ
      2. ì œê³µëœ ë²•ì  ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€
      3. êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ì „ë¬¸ ë³€í˜¸ì‚¬ ìƒë‹´ ê¶Œìœ 
      
      ë‹µë³€:
    `

    console.log('ğŸ“‹ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ, ê¸¸ì´:', prompt?.length || 'unknown')

    const chatMessage = {
      role: 'user' as const,
      content: prompt,
    }

    console.log('ğŸ¤– GPT ì™„ë£Œ ìš”ì²­ ì‹œì‘...')
    if (wantsStream) {
      const responseStream = await openai.chat.completions.create({
        model: 'gpt-5-mini',
        messages: [chatMessage],
        stream: true,
      })

      console.log('ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘...')

      try {
        // Set headers for SSE with citations
        res.writeHead(200, {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          Connection: 'keep-alive',
        })

        // Send citation metadata first as a special message
        const citationData = {
          type: 'citations',
          sources: usedSections,
          query: sanitizedQuery,
          timestamp: new Date().toISOString(),
        }

        // Send citation info as a JSON comment that won't affect the stream
        res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
        console.log('ğŸ“š ì¸ìš© ì •ë³´ ì „ì†¡ ì™„ë£Œ:', usedSections.length, 'ê°œ ì†ŒìŠ¤')

        // Stream chunks from the official OpenAI SDK
        let chunkCount = 0
        for await (const chunk of responseStream) {
          const delta = chunk.choices?.[0]?.delta?.content
          if (delta) {
            chunkCount++
            res.write(delta)
          }
        }
        console.log('âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ, ì´ ì²­í¬:', chunkCount)
        res.write(`\n\n<!-- END_CITATIONS: ${usedSections.length} sources used -->`)
        res.end()
      } catch (streamErr) {
        console.error('ğŸš¨ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', streamErr)
        if (!res.headersSent) {
          res.status(500).json({ error: 'Streaming failed' })
        } else if (!res.writableEnded) {
          res.write(`\n\n<!-- STREAM_ERROR: Streaming failed -->`)
          res.end()
        }
      }
    } else {
      console.log('ğŸ§© ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‘ë‹µ ìƒì„±...')
      const completion = await openai.chat.completions.create({
        model: 'gpt-5-mini',
        messages: [chatMessage],
        // stream disabled
      })

      const answer = completion.choices?.[0]?.message?.content ?? ''

      // Frontend expects plain text with embedded citation comments, not JSON
      res.writeHead(200, {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      })

      const citationData = {
        type: 'citations',
        sources: usedSections,
        query: sanitizedQuery,
        timestamp: new Date().toISOString(),
      }

      res.write(`<!-- CITATIONS: ${JSON.stringify(citationData)} -->\n`)
      res.write(answer)
      res.write(`\n\n<!-- END_CITATIONS: ${usedSections.length} sources used -->`)
      res.end()
    }
  } catch (err: unknown) {
    console.log('ğŸ’¥ API ì˜¤ë¥˜ ë°œìƒ:', err)
    if (err instanceof UserError) {
      console.log('ğŸ‘¤ ì‚¬ìš©ì ì˜¤ë¥˜:', err.message, err.data)
      res.status(400).json({
        error: err.message,
        data: err.data,
      })
    } else if (err instanceof ApplicationError) {
      // Print out application errors with their additional data
      console.error(`ğŸ”§ ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜¤ë¥˜: ${err.message}: ${JSON.stringify(err.data)}`)
      res.status(500).json({
        error: 'There was an error processing your request',
      })
    } else {
      // Print out unexpected errors as is to help with debugging
      console.error('ğŸš¨ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜:', err)
      res.status(500).json({
        error: 'There was an error processing your request',
      })
    }
  }
}
